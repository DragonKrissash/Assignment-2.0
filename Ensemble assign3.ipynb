{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075fcf88-1737-4c4d-a412-d00433951524",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b7de1c-0fdd-46b3-aaf3-890a6518006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "A1. Random forest regressor is a supervised machine learning algorithm that is used for regression tasks. It\n",
    "    works by creating multiple decision trees during training and outputting the mean prediction of the \n",
    "    individual trees for regression. It is a powerful ensemble learning method for regression tasks that\n",
    "    leverages bagging and feature randomness to create accurate and robust model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6f282d-43be-4e8a-a0a4-098ed0dd53d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. How does Random Forest Regressor reduce the risk of overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed99cc7b-54c5-4e51-aca6-096bcfe0bd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "A2. Forest regressor averages predictions across many decision trees, the model reduces variance and avoids\n",
    "    overfitting to noise or outliers that could impact a single tree. \n",
    "    \n",
    "    Bagging - Bootstrap sampling of the training data for each tree further decorrelates the trees to prevent\n",
    "    overfitting. \n",
    "    \n",
    "    By selecting a random subset of features to consider for splits at each node, it prevents trees from \n",
    "    being biased towards a few strong features. This diversity reduces overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f1ca45-602d-4aa6-a1ce-e2d90b442070",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e02e480-2f65-487a-930a-db7bb61fbbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "A3. The random forest regressor aggregates the predictions of multiple decisions trees by taking average.\n",
    "    Multiple decision trees are trained using bootstrap sampling of training data and random subset of \n",
    "    features. \n",
    "    Each tree makes a prediction for a sample.\n",
    "    The predictions of all individual trees are averages to make the overall prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3b4ca4-d573-4e28-bbea-620b3bdaa58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What are the hyperparameters of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8c0510-25e6-462b-bb04-d43bf4b262e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "A4. The hyperparameter of random forest regressor are:\n",
    "    n_estimators - The number of trees in the forest.\n",
    "    max_features - The number of random features to consider when splitting a node. \n",
    "    max_depth - The maximum depth of each tree.\n",
    "    n_jobs - Number of jobs to run in parallel while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5abdbb-8bf2-42bd-bac5-3adcb6ece294",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2897ba6-fb25-453d-ad20-6485b46e7860",
   "metadata": {},
   "outputs": [],
   "source": [
    "A5. The main differences are:\n",
    "    Random forest is an ensemble technique that aggregates predictions from multiple decision trees, while \n",
    "    decision tree is single.\n",
    "    Random forest trains each tree which bootstrapped subset of features and data while decision tree trains\n",
    "    on entire data.\n",
    "    When splitting nodes, random forest selects random subset of features to consider while decision tree\n",
    "    can evaluate on all features.\n",
    "    Random forest averages the prediction from multiple trees while decision tree relies on single tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7ab617-6d80-4ffc-b556-d14e1db67542",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. What are the advantages and disadvantages of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae20bbc5-1616-4759-bc69-7fcddd312cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "A6. Advantages - High prediction accuracy due to ensemble learning.\n",
    "    Robust to overfitting due to bagging, feature randomness and model averaging.\n",
    "    Handles nonlinear relationships and high dimensional data well.\n",
    "    Handles missing values and maintains accuracy with missing data.\n",
    "    \n",
    "    Disadvantages - Prone to being overly complex and slower to train due to multiple trees.\n",
    "    Loses interpretability compared to a single decision tree.\n",
    "    Can overfit if individual trees are too deep or narrow. \n",
    "    Requires more hyperparameters to tune compared to decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b11731-81a4-498d-bc6d-26d470111e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. What is the output of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5723e2f-7847-46e9-a291-bd24a5396677",
   "metadata": {},
   "outputs": [],
   "source": [
    "A7. The output of a random forest regressor is a numerical/continuous value predicting the target variable \n",
    "    for a given observation. \n",
    "    Each decision tree in the forest makes a numerical prediction for a given observation.\n",
    "    These predictions from all the individual trees are averaged to get the overall prediction.\n",
    "    For a regression problem, this final output is a single numerical value (not a class or category).\n",
    "    The value corresponds to the predicted target variable for the input observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9335ee-4cfe-43b1-bca8-5bac5c1215f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. Can Random Forest Regressor be used for classification tasks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770c4248-06ec-4093-b91d-1d03a207c53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "A8. No random forest regressor cannot be used for classification. Is is designed specifically for regression\n",
    "    problems where target variable is numeric."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
