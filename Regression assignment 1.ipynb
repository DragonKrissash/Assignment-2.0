{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48e1952-8189-41b7-b50a-48ae52508fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an\n",
    "example of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbbabbf-e6e9-46f2-a05e-6ff280d4711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "A1. Simple linear regression is a statistical method used to relation between one dependent and one \n",
    "    independent variable. It aims to find the linear equation that best fits the data points, allowing us to \n",
    "    make predictions or understand the relation between them.\n",
    "    y= β0 + β1 * x + ε\n",
    "    \n",
    "    Ex: If we want to find a student's exam score based on the number of hours studied. We can use the simple\n",
    "    linear regression to predict exam scores based on number of hours studied.\n",
    "    \n",
    "    Multiple linear regression includes more than one independent variable. It is used when there are multiple\n",
    "    predictors influencing a single dependent variable. \n",
    "    y=β0 + β1*x1 + β2*x2 + … + βn*xn + ε\n",
    "    \n",
    "    Ex: If we are predicting the price of a house based on its size, no of rooms, no of bathrooms then it is\n",
    "    multiple linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4320ed4-4ff4-4bea-975a-0df9ef3a75b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in\n",
    "a given dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830551b8-b3d7-4352-9e11-a3bdbc55c09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "A2. The assumptions of linear regression are:\n",
    "    \n",
    "    Linear relationship - The relation between independent and dependent variable should be linear. This can\n",
    "    be checked by plotting the variables and looking for a linear trend.\n",
    "    \n",
    "    No or little multiple collinearity - The independent variables should not be highly correlated with each\n",
    "    other. Multicollinearity can be checked by calculating variance inflation factors which should be less.\n",
    "    \n",
    "    Normally distributed errors - The error terms should follow a normal distribution. A histogram of residuals\n",
    "    can be checked to see if they are normally distributed. The Jarque - Bera test can be used to check normality.\n",
    "    \n",
    "    No influential observations - The model should not be influenced by small number of observations. Influence \n",
    "    can be measured by Cook's distance. Observations with very high Cook's distance may require further \n",
    "    investigation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d9300c-1ae8-4e8e-8c19-332b345adcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using\n",
    "a real-world scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4f11eb-048d-433c-af34-c9a9c03ebcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "A3. The slope and intercept have intuitive interpretation in a linear regression model. \n",
    "    Real world scenario - We are building a model to predict home price based on their size in square feet. \n",
    "    Price = B0 + B1*size \n",
    "    Where B0 is intercept and B1 is slope. The intercept gives us the price when the size is 0 which is not \n",
    "    true in real world but gives us a baseline. The slope gives us the change in price for each additional\n",
    "    square foot. If B1 = 100, for every additional square foot, the predicted price increases by 100. \n",
    "    If B0 = 50,000 and B1 = 100, A 1000 sq foot home costs 50,000 + 1000*100 = 150,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb00340d-7347-403b-9fba-d18a4478549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecf171a-b6e8-48d4-a24b-a7332e1017d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "A4. Gradient descent is an optimization algorithm used to minimize cost function in machine learning. It works\n",
    "    by taking steps in the direction of steepest descent towards a minimum. \n",
    "    The goal is to find the weights/parameters that minimize a cost function. \n",
    "    Start with random weights and compute the gradient of the cost function. The gradient points in the \n",
    "    direction of steepest increase, so we move in the opposite direction.\n",
    "    Take a small step in that direction w = w0 - aJ where a is learning rate that controls step size. \n",
    "    Repeat this update rule iteratively until cost function converges to minimum. \n",
    "    \n",
    "    So in summary, gradient descent starts from an initial guess and goes downhill on the cost function \n",
    "    surface until it reaches a valley. This valley is the optimal set of parameters for the model. \n",
    "    \n",
    "    This is used extensively in machine learning for training models like linear regression, logistic \n",
    "    regression, neural network etc. The cost function and update rules are defined for each use case. \n",
    "    Gradient descent allows these models to fit their parameters to the training data by minimizing the cost\n",
    "    iteratively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c2e3da-e07f-4a9b-9994-8004ee2610e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7ac5a7-d0fa-44cb-8137-4f8c7d1cdaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "A5. Multiple linear regression is an extension of linear regression which allows modeling the linear \n",
    "    relationship between two or more explanatory independent variables and a dependent variable.\n",
    "    y = B0 + B1x1 + B2x2 + B3x3 + .... + Bnxn\n",
    "    \n",
    "    The differences are:\n",
    "        \n",
    "    There are multiple independent variables in multiple linear regression which allows modelling of more\n",
    "    complex relationships. \n",
    "    Each explanatory variable has its own coefficient which represent independent contribution of each \n",
    "    variable to the response. \n",
    "    The model fitting process is still linear in parameters but algebra is multidimensional instead of two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94be0196-7277-4c07-92a3-40612460d31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and\n",
    "address this issue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2124f4-43d1-4fdb-92be-652d3bcd0bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "A6. Multicollinearity refers to a situation in multiple regression where two or more independent variables \n",
    "    are highly correlated with each other. This can pose problem in model estimation and interpretation. \n",
    "    \n",
    "    Ways to detect multcollinearity -\n",
    "    \n",
    "    High R squared but few significant coefficients - Multicollinearity can make it difficult for any single\n",
    "    variable to emerge as a strong predictor. \n",
    "    High correlation between explanatory variables - This directly indicates collinear relations.\n",
    "    Variance inflation factors which are greater than 5 or 10.\n",
    "    Eigen value analysis - Multicollinearity is present if the correlation matrix has eigenvalues close to 0.\n",
    "    \n",
    "    Ways to address multicollinearity - \n",
    "    Removing highly correlated variables - Drop one of the problematic variables from the model. \n",
    "    Combining variables - Transform correlated variables into a single predictor. \n",
    "    Adding more data - Multi collinearity can be a problem with small sample sizes, more data can reduce its \n",
    "    impact. \n",
    "    Regularization - Techniques like ridge regression and lasso shrink coefficients and can reduce effects \n",
    "    of collinearity. \n",
    "    Principal component analysis - Transform correlated variables into orthogonal principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00bd7e5-9c27-42df-b99f-eb3bbd0c92fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. Describe the polynomial regression model. How is it different from linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45830a7c-964f-4fcf-a150-778f43d741a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "A7. It is a type of linear regression where the relation between the independent variable x and dependent\n",
    "    variable y is in the nth degree. \n",
    "    y = B0 + B1*x1 + B2*x2 + B3*x3 + ... +Bn*xn\n",
    "    \n",
    "    The differences:\n",
    "    This includes the additional terms like x2, x3, etc. This allows modeling non - linear relationships, which\n",
    "    a linear model cannot capture. \n",
    "    While linear regression fits a straight line model, polynomial regression can fit curves and complex shapes.\n",
    "    Polynomial models have more coefficients to estimate the shape of the curve while linear model have only \n",
    "    slope and intercept.\n",
    "    Increasing polynomial degree can lead to overfitting, so polynomial degree is carefully selected through\n",
    "    validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a2f00c-6b89-42f2-ace0-a8944937f11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. What are the advantages and disadvantages of polynomial regression compared to linear\n",
    "regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318a6541-3fab-4033-acdd-2e427cb88188",
   "metadata": {},
   "outputs": [],
   "source": [
    "A8. Advantages - \n",
    "    Can model non - linear relationships. Useful when the true relationship is non - linear.\n",
    "    Provides a better fit to data with curves or complex shapes.\n",
    "    Simple to implement as it still uses linear regression methodology.\n",
    "    Works well with few data points. \n",
    "    \n",
    "    Disadvantages -\n",
    "    Potential for overfitting with higher degree polynomial. \n",
    "    More complex models are harder to interpret. \n",
    "    Performance heavily depends on selecting the right polynomial degree. \n",
    "    Can have high variance and sensitivity to outliers. \n",
    "    \n",
    "    Polynomial regression can be preferred when:\n",
    "    There is strong non - linear behaviour in the data which a linear model cannot capture.\n",
    "    The data has smooth curves which can be explained by low degree polynomials.\n",
    "    There are not too many features, to avoid very complex high degree polynomials.\n",
    "    Getting additional data to fit linear is difficult so need a flexible model from a limited data.\n",
    "    Interpretability of the model is not a major concern."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
