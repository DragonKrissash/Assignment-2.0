{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51e5471-5945-43a5-b60f-3ff50410bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Elastic Net Regression and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588880a6-f45e-4cac-94bd-1c1ab6f7de56",
   "metadata": {},
   "outputs": [],
   "source": [
    "A1. Elastic net regression is a regularization technique which includes both Lasso and Ridge. \n",
    "    The differences are:\n",
    "        Elastic net has regularisation and does not overfit while linear regression may overfit.\n",
    "        Ridge has only L2 while Elastic net has both L1 and L2.\n",
    "        Ridge may perform well but has unimportant features while Lasso performs feature selection but may be \n",
    "        unstable. Elastic net combines both by using L1 and L2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96efef67-e08a-47b2-8795-6550b4123fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. How do you choose the optimal values of the regularization parameters for Elastic Net Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6896cad0-615a-44ca-a67f-bb286a1c7d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "A2. There are few techiniques to find optimal values for alpha and lambda.\n",
    "    Grid search - Try different values of alpha and lambda and evaluate model performance on validation set.\n",
    "    Choose the values that optimize the validation techniques.\n",
    "    Cross - validation - Split data into folds, train model with different alpha and lambda values and validate\n",
    "    on each fold. Choose values that optimize on cross - validation metric.\n",
    "    Bayesian optimization - Use a Bayesian optimization algorithm to strategically search for optimal α, λ \n",
    "    values based on previous results.\n",
    "    Analyze coefficient paths - Plot coefficient paths for different values of α and λ. Choose values based \n",
    "    on desired sparsity and coefficient behavior.\n",
    "    Model-based methods - Some methods like AIC/BIC approximate the model evidence p(D|α,λ) to find optimal \n",
    "    values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1095a87c-d3f1-493f-9ae8-9dbbfee95b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What are the advantages and disadvantages of Elastic Net Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1da659-c9b6-4340-a760-07e55e7a3493",
   "metadata": {},
   "outputs": [],
   "source": [
    "A3. Advantages:\n",
    "    Performs feature selection and shrinkage automatically.\n",
    "    Overcomes the limitations of Lasso and Ridge.\n",
    "    More stable variable selection than Lasso and Ridge.\n",
    "    Less prone to overfitting compared to linear.\n",
    "    Can perform well even with highly correlated predictor variable.\n",
    "    \n",
    "    Disadvantages:\n",
    "    More computationally intensive than Lasso or Ridge.\n",
    "    Requires careful tuning of alpha and lambda.\n",
    "    Tendency to select more variables than required due to ridge.\n",
    "    Can overfit if not properly tuned.\n",
    "    Coefficient estimates exhibit bias due to regularization penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a2bdfa-3fd9-463c-b2d5-38cc6d18395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What are some common use cases for Elastic Net Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e402348-f39f-4bd2-b082-0b1a784b5752",
   "metadata": {},
   "outputs": [],
   "source": [
    "A4. If there are high dimensional data with many predictors, elastic net perform automatic variable selection\n",
    "    to reduce overfitting.\n",
    "    When there are highly correlated variables we need to use elastic net as Lasso selects one variable.\n",
    "    When we require a mix of Lasso and Ridge properties we need elastic net.\n",
    "    When we require model stability more than feature selection we need to use elastic net instead of lasso.\n",
    "    When we require a balance between bias and variance we need elastic net as ridge provides high bias, lasso\n",
    "    provides high variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c85ba60-fdc2-478e-b420-0735bd14f4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. How do you interpret the coefficients in Elastic Net Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a8cbee-8ba8-4e6e-81bb-dba5e0f128f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "A5. Coefficients are shrunk towards zero due to L1 and L2.\n",
    "    Variables with non zero coefficients are selected by model, but L1 penalty causes many small coefficients \n",
    "    to be set exactly to zero.\n",
    "    The relative magnitude of non zero coefficients can be interpreted just like linear regression coefficients\n",
    "    for comparing predictors.\n",
    "    To recover unbiased values we can refit the model on the selected variables without regularization penalties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf629465-f157-40b5-b3e9-5cba1551c4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. How do you handle missing values when using Elastic Net Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b074027-5f20-4478-83ec-55720d1870c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "A6. We can simply remove any samples or rows with missing predictor values.\n",
    "    We can use imputation methods like mean, mode, or kNN imputation to fill in the missing values.\n",
    "    We can use advanced methods like MICE that generate multiple imputed datasets and combine elastic net models\n",
    "    built on each.\n",
    "    We can add an indicator variable for missing values and let the model learn from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fee294-6501-4e9b-8bfd-5f8ae2db2a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. How do you use Elastic Net Regression for feature selection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6247f128-d181-47d6-87be-53c61a035142",
   "metadata": {},
   "outputs": [],
   "source": [
    "A7. First we need to preprocess the data that is check missing values, impute, encode categorical values, scale\n",
    "    or standardize the numerical features. \n",
    "    Split the data into training and validation set.\n",
    "    Find the appropriate alpha and lambda values by checking with lot of values.\n",
    "    Refit the model with lambda and alpha.\n",
    "    Select the features that have non zero coefficients in the fitted model.\n",
    "    Evaluate the model performance with metrics like RMSE, R2 etc.\n",
    "    Eliminate the features with lowest coefficients and stop when the model starts to degrade. \n",
    "    Retrain the model on full dataset and validate the data on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3ceaed-dba2-4666-ae33-7ef5dba3dd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. How do you pickle and unpickle a trained Elastic Net Regression model in Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a361be33-f5b4-4d79-b2c2-42d334259464",
   "metadata": {},
   "outputs": [],
   "source": [
    "A8. To pickle a data:\n",
    "    First we need to have a model let's say that we have elastic net model. \n",
    "    We need to train and fit the training data using ElasticNet() and fit().\n",
    "    We need to open a file for writing byte ('wb') and use pickle.dump() to serialize the model to the file.\n",
    "    \n",
    "    To unpickle a data:\n",
    "    We need to load or open the file in read byte mode and use pickle.load() to deserialize the pickled model. \n",
    "    The unpickled model can now be used to make predictions on new data using predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bf1d9d-f9e1-4e97-a589-478cb40616e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9. What is the purpose of pickling a model in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26ec28e-9ccc-4234-8ff1-3a15aa34160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "A9. The main purposes of pickling a model are:\n",
    "    Saving new models to disk and reused instead of training new models every time.\n",
    "    We can pickle models at various stages to snapshot progress or compare versions.\n",
    "    Loading pickled models retains hyperparameters/weights that deliver results equivalent to original model.\n",
    "    SKip repeated training by loading pickle for model development iterations or experiments.\n",
    "    Allows sharing of trained models to different teams/organizations without sharing data. \n",
    "    No need to keep entire model in memory when not in active use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
