{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893b11dd-7a57-4237-9324-3c4dd48d6320",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Explain the difference between linear regression and logistic regression models. Provide an example of\n",
    "a scenario where logistic regression would be more appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedf9379-dddd-49cb-b842-c2c44452c67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A1. Linear regression is used when the target variable is continuous/quantitative. It models the relationship\n",
    "    between one or more independent variables and a continuous dependent variable.\n",
    "    Ex: House price based on area and no of rooms.\n",
    "    \n",
    "    Logistic regression is used when the target variable is categorical/qualitative. It models the relationship\n",
    "    between one or more independent variables and a binary categorical variable. \n",
    "    Ex: Predicting if an email is spam or not spam based on text in the mail.\n",
    "    \n",
    "    Logistic regression would be more appropriate than linear regression in a binary classification where the \n",
    "    goal is to predict which of two categories an observation belongs to.\n",
    "    Ex: Logistic regression would be used to predict if a patient has a disease or not based on symptons. The \n",
    "    target variable is binary, sick/not sick rather than continuous, so logistic regression is better suited \n",
    "    than linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddae30ac-4b57-41d7-84fb-8d05fa3dee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What is the cost function used in logistic regression, and how is it optimized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d63cbcd-9346-43c6-8152-34e13bd73808",
   "metadata": {},
   "outputs": [],
   "source": [
    "A2. Logistic regression uses a different cost function than linear because of binary categorical feature of \n",
    "    target variable. Specificall, logistic regression uses the log loss or cross entropy function as its cost\n",
    "    function. \n",
    "    The log loss function measures the difference between actual class labels and the predicted probabilities\n",
    "    for each class. It penalizes the predictions which are confidently wrong. The goal is to minimize the log\n",
    "    loss, which is done using an optimization algorithm like gradient descent.\n",
    "    The log loss = (y log(p) + (1 - y) log(1 - p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d6456d-ff14-4519-993d-4b4d44335fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. Explain the concept of regularization in logistic regression and how it helps prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6a95ac-3a54-4c65-bb63-37c0b9eeebe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "A3. Regularization is a technique used in logistic regression to reduce overfitting. This works by adding\n",
    "    a penalty term like L1 or L2. \n",
    "    L1 adds a penalty term equal to magnitude of coefficients which forces many coefficients to become zero.\n",
    "    L2 adds a penalty term equal to square of magnitude of coefficients which shrinks coefficients towards \n",
    "    zero and reduce model complexity.\n",
    "    With regularization logistic regression not only minimizes the cost function but also keeps the coefficient\n",
    "    values relatively low. This contrains the model reduce the overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0912bf-0678-4c2f-98aa-fd6a909ddf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What is the ROC curve, and how is it used to evaluate the performance of the logistic regression\n",
    "model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7e99b4-d5dd-4633-925c-1c7dde62bef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "A4. The ROC (receiver operating characteristic) curve is a graphical plot that illustrates the performance \n",
    "    of a binary classifier like logistic regression. It is used to evaluate and compare classification model.\n",
    "    The ROC curve plots the true positive rate against the false positive rate at different classification\n",
    "    threshold. \n",
    "    TPR or sensitivity measures the proportion of actual positives that are correctly identified. \n",
    "    FPR or -1 specificity measures the proportion of actual negatives that are incorrectly classified as positive.\n",
    "    \n",
    "    An excellent model will maximize TPR and minimize FPR. This is achieved by having the ROC curve go upwards and\n",
    "    to the left quickly. The closer is the ROC curve to the upper left corner, better the model.\n",
    "    \n",
    "    The area under the ROC curve provides an aggregate numerical measure of model's performance. A perfect one \n",
    "    has AUC 1 and random classifier has AUC 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb707871-8c52-466f-aa84-ca7867a38617",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. What are some common techniques for feature selection in logistic regression? How do these\n",
    "techniques help improve the model's performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75116734-8a76-4751-b863-6e192e5db12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "A5. Correlation matrix - Examining the correlation coefficient features can screen for highly correlated \n",
    "    features. Keeping one feature from a highly correlated set reduces redundancy. \n",
    "    Regularization - Penalization methods like L1 and L2 automatically do feature selection by driving non - \n",
    "    significant coefficients to zero.\n",
    "    Recursive feature elimination - Recursively training models by eliminating the least useful features at \n",
    "    each iteration based on coefficient magnitude. \n",
    "    Model based selection - Comparing models with different subsets of features and selecting the optimal \n",
    "    subset based on performance metrics.\n",
    "    \n",
    "    These techniques improve model accuracy by removing irrelevant or misleading features.\n",
    "    They reduce overfitting by reducing model complexity.\n",
    "    Enhance model interpretability by retaining only important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c0f61-1e6d-4ac5-86a4-aec79fd2910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. How can you handle imbalanced datasets in logistic regression? What are some strategies for dealing\n",
    "with class imbalance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dd72fe-e658-48cd-8a5b-6a69624ee2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "A6. Class imbalance is when one class is significantly underrepresented compared to the other classes. This \n",
    "    can pose problems for logistic regression model as they may be biased towards majority class and have \n",
    "    poor predictive performance on minority class. We can handle the imbalance by:\n",
    "        We can oversample the minority class to match with the majority class. \n",
    "        We can undersample the majority class to attain class balance with minority.\n",
    "        We can use SMOTE and produce synthetic examples from minority class to match with majority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0272da6f-ed89-41b4-a39b-5d2ea5184c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. Can you discuss some common issues and challenges that may arise when implementing logistic\n",
    "regression, and how they can be addressed? For example, what can be done if there is multicollinearity\n",
    "among the independent variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1733d7c-8332-4b21-945b-93038cc87a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "A7. Multicollinearity - High correlation between independent can inflate standard errors and make coefficients\n",
    "    unstable. Fixes are removing redundant features, regularization and principal component analysis.\n",
    "    Overfitting - If Model fits training data too closely, we can use regularization, simplify model or add more\n",
    "    training data.\n",
    "    Underfitting - If model cannot capture relationship between features and target, we can try adding polynomial\n",
    "    terms, interaction terms to make model more flexible.\n",
    "    Class imbalance - If one class is more frequent than others. We can resample data, adjust class weights, change\n",
    "    evaluation metric."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
