{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471c5f56-5482-4db6-a7c5-2f0f1fcf5b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is an ensemble technique in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90683e88-a3e1-4094-afc1-7b1f6228963a",
   "metadata": {},
   "outputs": [],
   "source": [
    "A1. An ensemble technique in machine learning refers to use of multiple algorithms together to obtain better\n",
    "    predictive performance than could be obtained from any of the constituent learning algorithms alone. \n",
    "    The main benefit of using ensemble techniques is that by combining multiple methods we can get better\n",
    "    overall predictive accuracy than from a single model. This is because different models will not make the \n",
    "    same errors on test set. Ensembles make the predictions more robust - less sensitive to errors in any \n",
    "    single model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b87d478-d062-4235-bd54-b1519770d82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. Why are ensemble techniques used in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caf7df5-116a-4514-91b0-e9fa390a05f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "A2. Ensemble techniques are used in machine learning to:\n",
    "    Improve accuracy - Ensembles can help improve predictive performance by combining multiple models. \n",
    "    \n",
    "    Reduce variance - Ensembles like bagging and forests help reduce the variance of decision tree models. \n",
    "    Training multiple decision trees on different subsets of data can decrease reliance on any single tree \n",
    "    and improve stability.\n",
    "    \n",
    "    Robustness - Ensembles combine multiple techniques, so they are less prone to being negatively impacted\n",
    "    by weakness of any single model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04025641-39d9-4886-ac34-fd7bc15e0997",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What is bagging?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca7ccdf-70c1-48c1-83c6-690610869521",
   "metadata": {},
   "outputs": [],
   "source": [
    "A3. Bagging is short form for bootstrap aggregating, is an ensemble method to improve stability and accuracy\n",
    "    of machine learning algorithms. It reduces variance and helps avoid overfitting. \n",
    "    Bagging leverages bootstrap sampling and model averaging to create an ensemble that performs better than\n",
    "    a single model trained on whole dataset. This reduces overfitting and improves stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235c86a0-1ea7-45d7-86ec-ed961df09d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What is boosting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b224a1-c3e7-4915-80c5-994d7c821737",
   "metadata": {},
   "outputs": [],
   "source": [
    "A4. Boosting is an ensemble used to create a strong classifier from a number of weak classifiers. The key idea\n",
    "    is to train the model sequentially, with each new model focussing more on instances that the previous model\n",
    "    misclassified. Boosting helps reduce bias and works well with algorithms that have high variance. By \n",
    "    focussing on errors, boosting creates a very accurate combined model overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99f99f3-d031-4749-8004-da82a05d682a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. What are the benefits of using ensemble techniques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c66b16-16c8-4b4d-9d3c-9a98dc909786",
   "metadata": {},
   "outputs": [],
   "source": [
    "A5. The benefits are:\n",
    "    Improved accuracy - Ensembles tend to perform better than any of the individual model due to averaging \n",
    "    out biases and model variances.\n",
    "    \n",
    "    Robustness - Ensembles are less prone to overfitting on the training data compared to a single model. \n",
    "    Their predictions tend to generalize better to new data.\n",
    "    \n",
    "    Versatility - Ensembles can be built out of many different models allowing for creativity and flexibility.\n",
    "    \n",
    "    Confidence - Ensembles can provide better measures of confidence or uncertainty compared to individual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f0492e-2876-42ac-8727-c9622bcca0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Are ensemble techniques always better than individual models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6d7644-645d-46e5-b69e-95a6e7739f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "A6. No ensemble techniques are not always better than individual models as:\n",
    "    Increased training time - Training multiple models in an ensemble naturally takes greater computation time\n",
    "    and resources than training a single model.\n",
    "    \n",
    "    Decreased interpretability - Ensembles combine multiple models so overall ensemble model is more complex.\n",
    "    \n",
    "    Overhead of design - Constructing ensembles requires more design decisions compared to using a single model,\n",
    "    like choosing algorithm, hyper parameter tuning etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7b5d3b-b2d0-48a7-b475-e5938b092850",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. How is the confidence interval calculated using bootstrap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e982b49b-0c0c-4b10-a724-1e8b79e6449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "A7. The steps are:\n",
    "    \n",
    "    Randomly sample with replacement from the original dataset to create B new datasets of same size.\n",
    "    \n",
    "    For each new bootstrap dataset, calculate the statistic of interest.\n",
    "    \n",
    "    Sort the B values from low to high and indentify the percentiles representing the lower and upper bounds.\n",
    "    \n",
    "    The range between the percentiles gives the 95% confidence interval for the statistic. The wider the CI\n",
    "    more uncertain the estimate of statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a307d4d9-8e1f-403e-8b6d-73f15644d6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. How does bootstrap work and What are the steps involved in bootstrap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cc0dee-59c9-4ec8-b175-461774151734",
   "metadata": {},
   "outputs": [],
   "source": [
    "A8. Bootstrap is a statistical technique for estimating properties of a population by sampling with \n",
    "    replacement from the original dataset. It allows estimating statistics on a population by repeatedly \n",
    "    resampling a given dataset. \n",
    "    The steps are said in above question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ace26b8-9824-4d6d-9d7f-d59aae2490e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9. A researcher wants to estimate the mean height of a population of trees. They measure the height of a\n",
    "sample of 50 trees and obtain a mean height of 15 meters and a standard deviation of 2 meters. Use\n",
    "bootstrap to estimate the 95% confidence interval for the population mean height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5cdffcd-5855-4a20-a4b2-0edd89455478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "sample_ht=np.random.uniform(10,20,50)\n",
    "num_boot=10000\n",
    "boot_means=np.zeros(num_boot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37485bf3-ea68-486f-a3c6-354ded5b889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_boot):\n",
    "    boot_sample=np.random.choice(sample_ht,size=50,replace=True)\n",
    "    boot_means[i]=np.mean(boot_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1159e9f0-9391-4581-9834-8f3e3c83b342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval for Mean Height: [14.63999927 16.13786945]\n"
     ]
    }
   ],
   "source": [
    "con_int=np.percentile(boot_means,[2.5,97.5])\n",
    "print(\"95% Confidence Interval for Mean Height:\", con_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e073cbc-e1f1-471b-b753-835bb24b5335",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
