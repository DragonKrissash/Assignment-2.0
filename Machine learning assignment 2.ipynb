{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4a03bb-6d87-4525-97ed-b83ccad6e2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how\n",
    "can they be mitigated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14d30ed-24ad-49e1-af9b-f0fb38f97580",
   "metadata": {},
   "outputs": [],
   "source": [
    "A1. Overfitting - It occurs when the model learns the training data too well, capturing noise or random \n",
    "    fluctuations in the data rather than general patterns. In the result, the model runs well on test data\n",
    "    but fails on new or unseen data.\n",
    "    \n",
    "    Consequences - It performs well on test data but very poorly on new data making it less useful in real world.\n",
    "    Overfit models tend to have excessive complexity, making them harder to interpret and maintain.\n",
    "    \n",
    "    Mitigation - We can use techniques like k fold cross validation to assess the model's performance on \n",
    "    multiple subsets of the data and prevent overfitting.\n",
    "    Reduce the number of irrelevant or redundant features to prevent model from memorizing noise.\n",
    "    \n",
    "    Underfitting - It occurs when the model doesn't learn well from training data and performs poorly on test\n",
    "    as well as new, unseen data. \n",
    "    \n",
    "    Consequences - The model's predictions are inaccurate on both training and validation datasets. \n",
    "    Model may not be able to capture the underlying patterns, leading to suboptimal performance.\n",
    "    \n",
    "    Mitigation - Increase the model's complexity by adding more neurons or layers in neural networks or using\n",
    "    more complex algorithms.\n",
    "    Ensure that relevant and informative features are included in the dataset to help the model learn better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481b043d-3d15-488c-8eb2-c6ee28ab07ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2: How can we reduce overfitting? Explain in brief."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d46620e-c9ab-4d22-8baa-38e196a8ada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "A2. Cross-validation: Use techniques like k-fold cross-validation to split your dataset into multiple \n",
    "    subsets and assess the model's performance on different combinations of training and validation data. \n",
    "    This helps identify if the model is overfitting to a specific subset of the data.\n",
    "    \n",
    "    Feature selection: Carefully select relevant and informative features and discard irrelevant or \n",
    "    redundant ones. Simplifying the feature set can help the model focus on the most important \n",
    "    relationships in the data.\n",
    "    \n",
    "    Data augmentation - Increase the size of the training set by creating modified versions of the existing\n",
    "    data. This helps the model generalize better and reduces the risk of overfitting to specific instances \n",
    "    in the data.\n",
    "    \n",
    "    Early stopping - Monitor the model's performance during training and stop training when the performance\n",
    "    on the validation set starts to degrade. This prevents the model from memorizing the training data and \n",
    "    improves generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56763a83-d8e0-4ec2-9a0d-f52d64848604",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3: Explain underfitting. List scenarios where underfitting can occur in ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c4309d-652e-442e-991f-3c929bbde6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "A3. Underfitting occurs when the model is too simplistic to learn and capture the underlying patterns in data.\n",
    "    Instead of learning the relationshipsand complexities present in data, an underfit model produces overly\n",
    "    generalized or coarse predictions. It performs poorly on both training as well as test dataset.\n",
    "    Underfitting occurs when the model is too simple or has limited capacity to represent the underlying data\n",
    "    distribution, it fails to learn the underlying data distribution, it fails to learn intricate patterns and\n",
    "    underfits the data.\n",
    "    If the available training data is too small or not representative of the underlying data distribution, the \n",
    "    model may struggle to find meaningful patterns and underperform.\n",
    "    Applying excess of regularization, such as strong l1 or l2 regularization, can overly penalize the model's\n",
    "    parameters, leading to underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a620fc-33fc-4e5a-82c1-90b1242a2b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and\n",
    "variance, and how do they affect model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23619a64-0ede-4936-8d36-12f9bfbf4e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "A4. The bias-variance tradeoff is a fundamental concept in machine learning that deals with the tradeoff\n",
    "    between two types of errors a model can make: bias error and variance error.\n",
    "    \n",
    "    Bias - It is a error introduced by approximating a complex real world problem with a simplified model.\n",
    "    A model with high bias tends to underfit the data, as it oversimplifies the relationships between the \n",
    "    input feaatures and target output. High bias typically result from using a model that is too simplistic\n",
    "    or making strong assumptions that do not align well with the true underlying data distribution.\n",
    "    \n",
    "    Variance - Variance refers to the error introduced due to the model's sensitivity to variations in the \n",
    "    training data. A model with high variance fits the training data too well, capturing noise and random \n",
    "    fluctuations instead of general patterns. Consequently, such a model performs well on the training set \n",
    "    but poorly on new, unseen data. High variance is often associated with overfitting.\n",
    "    \n",
    "    As we decrease bias (make the model more complex), the variance tends to increase. This means the model\n",
    "    is more likely to fit the training data well, but it may overfit and perform poorly on new data.\n",
    "    As we decrease the variance (make the model less complex), the bias tends to increase. This means model\n",
    "    becomes more robust to variations in the training data but may underfit and fail to capture the true \n",
    "    underlying patterns.\n",
    "    \n",
    "    The bias-variance tradeoff directly affects the overall performance of a machine learning model. Ideally\n",
    "    we want a model that strikes a balance between bias and variance to achieve good generalisation.\n",
    "    \n",
    "    If the model has high bias, low variance it will underfit the data, resulting in poor performance on both\n",
    "    the training and test datasets.\n",
    "    If the model has low bias, high variance, it will overfit the data, performing very well on training but\n",
    "    poorly on unseen data.\n",
    "    The optimal model has moderate bias and moderate variance, striking a balance that allows it to generalize\n",
    "    well to new data while still capturing the essential patterns in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e9626f-27ce-4138-a962-58d2d9193371",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models.\n",
    "How can you determine whether your model is overfitting or underfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b69773-1a67-49cd-81e3-9e8531776650",
   "metadata": {},
   "outputs": [],
   "source": [
    "A5: Visual interpretaton - We can plot the model's performance metrics on train data, validation data, test data.\n",
    "    If the model performs well on train data and it's performance decreases with subsequent validation and test\n",
    "    data then it is overfitting.\n",
    "    However if the model performs low on train data and also subsequent validation and test data then it is \n",
    "    underfitting.\n",
    "    \n",
    "    Learning curves - Learning curves show the model's performance as a function of size of training dataset. By \n",
    "    plotting the training and validation performance against number of training samples, we can identify patterns\n",
    "    that indicate underfitting or overfitting.\n",
    "    \n",
    "    Cross validation - Using techniques like k-fold cross validation, you can assess the model's performance on\n",
    "    multiple subsets of data. If the model performs well on average but shows significant fluctuation in performance\n",
    "    across different folds, it might be overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28f0a19-1885-4301-a5a8-562637240295",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias\n",
    "and high variance models, and how do they differ in terms of their performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9ae518-00c3-49a2-ba26-a4f547c2887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A6: Bias - It is the error introduced by approximating a complex real world problem with a simplified model.\n",
    "    A model with high bias tends to underfit the data, as it oversimplifies the relationships between the input\n",
    "    features and the target outputs.\n",
    "    Variance - It refers to the error introduced in model's sensitivity to variations in the training data. A\n",
    "    model with high variance fits the data too well, capturing noise and random fluctuations instead of general \n",
    "    patterns.\n",
    "    \n",
    "    Bias and variance are both types of errors that affect a model's ability to generalize to new data.\n",
    "    High bias models tend to be oversimplistic and miss important relationships in data, leading to poor performance\n",
    "    on both the training and test dataset. \n",
    "    High variance dataset tend to be overly complex and capture noise or fluctuations in the training data, leading\n",
    "    to excellent performance on train data but poor on new or unseen data.\n",
    "    \n",
    "    Ex: High bias models - Linear regression with few features, very shallow decision trees and simple linear \n",
    "    classifiers can be examples of high bias models. These models may struggle to capture the true relationships\n",
    "    in the data and perform poorly on both training and test data.\n",
    "    \n",
    "        High variance models - Deep neural networks with many layers and neurons, decision trees with high dept\n",
    "        and low regularization, and k-nearest neighbours with a low value of k can be examples of high variance \n",
    "        models. These model may fit the training data very well but generalize poorly to new data leading to high\n",
    "        accuracy on training set but lower on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d925232e-5ac0-4f5a-b7d7-db00d482a62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe\n",
    "some common regularization techniques and how they work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995103e4-48f6-4aba-bdd5-425d6518b22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "A7: Regularization is a set of techniques used in machine learning to prevent overfitting, a situation where\n",
    "    a model becomes too complex and fits the noise or random fluctuations in the training data, leading to \n",
    "    poor generalization on new data. Regularization adds a penalty term to the model's loss function, \n",
    "    discouraging it from fitting noise and encouraging simpler models that capture the essential patterns in \n",
    "    the data.\n",
    "    \n",
    "    L1 Regularization (Lasso)- Adds sum of absoulute's values of model's coefficients as penalty term to loss function. \n",
    "    It encourages some of the co-efficients to become exactly 0, effectively performing feature selection and \n",
    "    leading to a sparse model. L1 regularization can drive less important features to have a coefficient of zero, \n",
    "    removing them from the model and simplifying it.\n",
    "    \n",
    "    L2 Regularisation (Ridge) - Adds the sum of square of the model's co-effitcient as a penalty term to the loss\n",
    "    function. It discourages large coefficients and smooths the impact of different features. L2 Regularization\n",
    "    leads to models with small but non-zero coefficients for all features, as it prefers to keep all features \n",
    "    instead of selecting only a few.\n",
    "    \n",
    "    Droput - It is a regularization technique used primarily in neural networks. During training, dropout randomly \n",
    "    deactivates a fraction of neurons in each layer, forcing the network to learn robust features which are not\n",
    "    dependent on specific neurons. This prevents model from overfitting to specific feature and improves generalisation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
